{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11279983,"sourceType":"datasetVersion","datasetId":7052194}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom imblearn.over_sampling import SMOTE\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier, StackingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"4cb451ec-d881-441b-8ef7-b4284994358e","_cell_guid":"9c868c39-037c-4a8a-8fec-e455030fadbe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:53.721768Z","iopub.execute_input":"2025-04-07T05:19:53.722113Z","iopub.status.idle":"2025-04-07T05:19:57.239393Z","shell.execute_reply.started":"2025-04-07T05:19:53.722060Z","shell.execute_reply":"2025-04-07T05:19:57.238473Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ------------------------------\n# 1. Data Preprocessing\n# ------------------------------\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/cricket-predictor/over_features.csv')\n\n# Create engineered features\ndf['pressure_index'] = df['dot_ball_pressure'] * df['required_desired_run_rate']\ndf['wicket_pressure'] = df['number_of_wickets_lost'] * df['required_desired_run_rate']\ndf['late_over_flag'] = (df['over'] > 15).astype(int)\ndf['bowler_pressure'] = df['current_bowler_economy'] * (df['bowler_wickets_in_match'] + 1)  # +1 to avoid zeros\ndf['aggressiveness_index'] = df['striker_strike_rate'] * (df['striker_boundaries_hit'] + 1)\n\n# Drop unneeded columns: match_id is an identifier and may not be useful.\n# Also, you can decide if you want to encode categorical variables like 'team' and 'match_phase'\ndf = df.drop(columns=['match_id'])\n\n# One-hot encode categorical columns if needed\ndf = pd.get_dummies(df, columns=['team', 'match_phase'], drop_first=True)\n\n# Separate features and target. Our target is 'wicket_next_over'\nX = df.drop(columns=['wicket_next_over'])\ny = df['wicket_next_over']","metadata":{"_uuid":"becc4b91-78e2-428a-8844-a9cff739c450","_cell_guid":"462c6a5b-7835-4fc3-ad96-58cd4488501c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:57.240353Z","iopub.execute_input":"2025-04-07T05:19:57.240833Z","iopub.status.idle":"2025-04-07T05:19:57.520865Z","shell.execute_reply.started":"2025-04-07T05:19:57.240801Z","shell.execute_reply":"2025-04-07T05:19:57.520040Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ------------------------------\n# 2. Train-Test Split & Scaling\n# ------------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Scale the features (important for models like SVM and KNN)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"_uuid":"2d02f5a8-c3fd-4846-baec-d885092fd92f","_cell_guid":"6f0c9a16-32dc-4e9f-a5da-a74e46c14c08","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:57.521932Z","iopub.execute_input":"2025-04-07T05:19:57.522340Z","iopub.status.idle":"2025-04-07T05:19:57.706472Z","shell.execute_reply.started":"2025-04-07T05:19:57.522303Z","shell.execute_reply":"2025-04-07T05:19:57.705342Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ------------------------------\n# 2.5. Addressing Class Imbalance with SMOTE\n# ------------------------------\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n\nprint(\"Class distribution before SMOTE:\", np.bincount(y_train))\nprint(\"Class distribution after SMOTE:\", np.bincount(y_train_balanced))","metadata":{"_uuid":"c0021d30-8a4a-4734-a7c9-ac4a4c189d97","_cell_guid":"5dc5a869-68d9-4dea-a71e-464c2a6fcdff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:57.709356Z","iopub.execute_input":"2025-04-07T05:19:57.709646Z","iopub.status.idle":"2025-04-07T05:19:58.133774Z","shell.execute_reply.started":"2025-04-07T05:19:57.709620Z","shell.execute_reply":"2025-04-07T05:19:58.132874Z"}},"outputs":[{"name":"stdout","text":"Class distribution before SMOTE: [23721 10166]\nClass distribution after SMOTE: [23721 23721]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ------------------------------\n# 3. Model Training and Evaluation\n# ------------------------------\n\n# Prepare a dictionary to store evaluation metrics for each model\nresults = {}\n\n# Helper function for printing metrics\ndef evaluate_model(name, y_true, y_pred, y_prob=None):\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, zero_division=0)\n    rec = recall_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else None\n    results[name] = {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1 Score': f1, 'ROC-AUC': auc}\n    print(f\"{name} -> Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1 Score: {f1:.3f}, ROC-AUC: {auc if auc is not None else 'N/A'}\")","metadata":{"_uuid":"92f0cba1-dd3f-4fa9-9c08-f93e669a3198","_cell_guid":"0d5fd2a1-ddae-45b4-a3e3-12a10e5129d6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:58.135403Z","iopub.execute_input":"2025-04-07T05:19:58.135746Z","iopub.status.idle":"2025-04-07T05:19:58.141641Z","shell.execute_reply.started":"2025-04-07T05:19:58.135718Z","shell.execute_reply":"2025-04-07T05:19:58.140615Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 3.1 Linear Regression (as a baseline classifier)\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_linreg = (lin_reg.predict(X_test_scaled) >= 0.5).astype(int)\nevaluate_model(\"Linear Regression\", y_test, y_pred_linreg, y_prob=lin_reg.predict(X_test_scaled))","metadata":{"_uuid":"2ebf6a2e-33a3-4432-8c0f-ffef8159e199","_cell_guid":"cf9eb63c-d7bc-4eb8-b37d-74bbdc530a4a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:58.142652Z","iopub.execute_input":"2025-04-07T05:19:58.143007Z","iopub.status.idle":"2025-04-07T05:19:58.376800Z","shell.execute_reply.started":"2025-04-07T05:19:58.142971Z","shell.execute_reply":"2025-04-07T05:19:58.375884Z"}},"outputs":[{"name":"stdout","text":"Linear Regression -> Accuracy: 0.608, Precision: 0.378, Recall: 0.471, F1 Score: 0.419, ROC-AUC: 0.5924727976404498\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 3.2 Logistic Regression\nlog_reg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\nlog_reg.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_log = log_reg.predict(X_test_scaled)\ny_prob_log = log_reg.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Logistic Regression\", y_test, y_pred_log, y_prob=y_prob_log)","metadata":{"_uuid":"0a910684-083c-44b2-a796-1666882ecd64","_cell_guid":"e8aec19d-81f5-4392-afcb-a9a22d6ad4d3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:58.377696Z","iopub.execute_input":"2025-04-07T05:19:58.378093Z","iopub.status.idle":"2025-04-07T05:19:58.627623Z","shell.execute_reply.started":"2025-04-07T05:19:58.378039Z","shell.execute_reply":"2025-04-07T05:19:58.626616Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression -> Accuracy: 0.608, Precision: 0.377, Recall: 0.472, F1 Score: 0.419, ROC-AUC: 0.5926535717650055\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 3.3 K-Nearest Neighbors (KNN)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_knn = knn.predict(X_test_scaled)\nevaluate_model(\"KNN\", y_test, y_pred_knn)","metadata":{"_uuid":"49977f2b-ae91-496b-bb1a-502df4fbcdd0","_cell_guid":"de33fd0e-77a8-4316-bb50-1beac0a107a5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:19:58.628578Z","iopub.execute_input":"2025-04-07T05:19:58.628849Z","iopub.status.idle":"2025-04-07T05:20:00.247501Z","shell.execute_reply.started":"2025-04-07T05:19:58.628825Z","shell.execute_reply":"2025-04-07T05:20:00.246442Z"}},"outputs":[{"name":"stdout","text":"KNN -> Accuracy: 0.522, Precision: 0.319, Recall: 0.520, F1 Score: 0.395, ROC-AUC: N/A\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 3.4 Decision Tree\ntree = DecisionTreeClassifier(class_weight='balanced', random_state=42)\ntree.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_tree = tree.predict(X_test_scaled)  # You can use X_test_scaled for consistency\ny_prob_tree = tree.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Decision Tree\", y_test, y_pred_tree, y_prob=y_prob_tree)","metadata":{"_uuid":"097b13de-de67-4d02-b9f5-bab5e7ab973d","_cell_guid":"9141ad5b-90a4-4e10-bcd4-c2eb4475a234","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:20:00.248435Z","iopub.execute_input":"2025-04-07T05:20:00.248709Z","iopub.status.idle":"2025-04-07T05:20:01.521687Z","shell.execute_reply.started":"2025-04-07T05:20:00.248685Z","shell.execute_reply":"2025-04-07T05:20:01.520800Z"}},"outputs":[{"name":"stdout","text":"Decision Tree -> Accuracy: 0.587, Precision: 0.323, Recall: 0.343, F1 Score: 0.333, ROC-AUC: 0.5179480179858644\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 3.6 Random Forest\nrf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\nrf.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_rf = rf.predict(X_test_scaled)\ny_prob_rf = rf.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Random Forest\", y_test, y_pred_rf, y_prob=y_prob_rf)","metadata":{"_uuid":"7a7e7006-7af9-4221-8cbe-a5108b773d90","_cell_guid":"edcfc81f-e3dc-43fa-88dc-841a4f4bfe28","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:20:01.522577Z","iopub.execute_input":"2025-04-07T05:20:01.522840Z","iopub.status.idle":"2025-04-07T05:20:14.443889Z","shell.execute_reply.started":"2025-04-07T05:20:01.522816Z","shell.execute_reply":"2025-04-07T05:20:14.442889Z"}},"outputs":[{"name":"stdout","text":"Random Forest -> Accuracy: 0.684, Precision: 0.432, Recall: 0.164, F1 Score: 0.237, ROC-AUC: 0.5658904767527793\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 3.7 Ensemble Method: Voting Classifier\nvoting_clf = VotingClassifier(\n    estimators=[('lr', log_reg), ('tree', tree), ('rf', rf)],\n    voting='soft'\n)\nvoting_clf.fit(X_train_balanced, y_train_balanced)  # Changed here: use balanced data\ny_pred_voting = voting_clf.predict(X_test_scaled)\ny_prob_voting = voting_clf.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Voting Classifier\", y_test, y_pred_voting, y_prob=y_prob_voting)","metadata":{"_uuid":"28000f39-d1c2-4da9-be93-66b3b08a96be","_cell_guid":"e74297fb-740e-4667-b7cb-470bd00336ec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:20:14.444857Z","iopub.execute_input":"2025-04-07T05:20:14.445228Z","iopub.status.idle":"2025-04-07T05:20:28.940562Z","shell.execute_reply.started":"2025-04-07T05:20:14.445189Z","shell.execute_reply":"2025-04-07T05:20:28.939562Z"}},"outputs":[{"name":"stdout","text":"Voting Classifier -> Accuracy: 0.588, Precision: 0.324, Recall: 0.345, F1 Score: 0.334, ROC-AUC: 0.560510207601668\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 3.8 K-Means Clustering (Unsupervised)\nkmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\nkmeans.fit(X_train_balanced)  # Changed here: using balanced data for clustering\nclusters_train = kmeans.labels_\n\n# Map clusters to the majority class in the balanced training data\nmapping = {}\nfor cluster in np.unique(clusters_train):\n    indices = np.where(clusters_train == cluster)[0]\n    majority_class = y_train_balanced.iloc[indices].mode()[0]\n    mapping[cluster] = majority_class\n\nclusters_test = kmeans.predict(X_test_scaled)\ny_pred_kmeans = np.array([mapping[cluster] for cluster in clusters_test])\nevaluate_model(\"KMeans Clustering\", y_test, y_pred_kmeans)","metadata":{"_uuid":"5bd06fd1-0d7b-41cf-a4b1-8d0db01611eb","_cell_guid":"d38e1ec6-5fbd-47b9-b443-427e0d7eca01","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:20:28.941417Z","iopub.execute_input":"2025-04-07T05:20:28.941679Z","iopub.status.idle":"2025-04-07T05:20:29.691806Z","shell.execute_reply.started":"2025-04-07T05:20:28.941654Z","shell.execute_reply":"2025-04-07T05:20:29.690769Z"}},"outputs":[{"name":"stdout","text":"KMeans Clustering -> Accuracy: 0.451, Precision: 0.315, Recall: 0.708, F1 Score: 0.436, ROC-AUC: N/A\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# SVM with RBF kernel\nsvm_model = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42)\nsvm_model.fit(X_train_balanced, y_train_balanced)\ny_pred_svm = svm_model.predict(X_test_scaled)\ny_prob_svm = svm_model.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"SVM (RBF)\", y_test, y_pred_svm, y_prob=y_prob_svm)","metadata":{"_uuid":"a2937f11-833b-4b73-a640-29cab4aea2d9","_cell_guid":"2c80c508-c3b5-4e2a-981c-65a0a2a85bce","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-07T05:20:29.694902Z","iopub.execute_input":"2025-04-07T05:20:29.695250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gaussian Naive Bayes\nnb_model = GaussianNB()\nnb_model.fit(X_train_balanced, y_train_balanced)\ny_pred_nb = nb_model.predict(X_test_scaled)\n# GaussianNB supports predict_proba, so we get probabilities for ROC-AUC calculation\ny_prob_nb = nb_model.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Gaussian Naive Bayes\", y_test, y_pred_nb, y_prob=y_prob_nb)","metadata":{"_uuid":"80cc4b49-a9d7-4a62-924e-21a7c424ed22","_cell_guid":"960a82a2-711b-49a5-b28b-999bfaeb104a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# AdaBoost using a simple Decision Tree as base estimator\nada_model = AdaBoostClassifier(\n    estimator=DecisionTreeClassifier(max_depth=1, class_weight='balanced', random_state=42),\n    n_estimators=50,\n    random_state=42\n)\nada_model.fit(X_train_balanced, y_train_balanced)\ny_pred_ada = ada_model.predict(X_test_scaled)\ny_prob_ada = ada_model.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"AdaBoost\", y_test, y_pred_ada, y_prob=y_prob_ada)","metadata":{"_uuid":"8769f0ae-0ed5-44fc-80a4-814af956b1c6","_cell_guid":"19a9d719-87b0-489a-81ad-07fab9e723b5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stacking Classifier with a mix of models\nstacking_estimators = [\n    ('lr', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)),\n    ('dt', DecisionTreeClassifier(class_weight='balanced', random_state=42)),\n    ('rf', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n]\nstacking_model = StackingClassifier(\n    estimators=stacking_estimators,\n    final_estimator=LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n)\nstacking_model.fit(X_train_balanced, y_train_balanced)\ny_pred_stack = stacking_model.predict(X_test_scaled)\ny_prob_stack = stacking_model.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Stacking Classifier\", y_test, y_pred_stack, y_prob=y_prob_stack)","metadata":{"_uuid":"b7a80dd8-e79e-4026-b208-72fb3944c7cf","_cell_guid":"8f373b94-7258-4f44-b3a7-6d061ca9d792","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define parameter grid for Logistic Regression using L1 and L2 penalties.\nparam_grid = {\n    'penalty': ['l1', 'l2'],\n    'C': [0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear']  # liblinear supports both l1 and l2 penalties.\n}\n\ngrid_log_reg = GridSearchCV(\n    LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n    param_grid,\n    cv=5,\n    scoring='f1',\n    n_jobs=-1\n)\ngrid_log_reg.fit(X_train_balanced, y_train_balanced)\nprint(\"Best parameters for Logistic Regression:\", grid_log_reg.best_params_)\nprint(\"Best F1 score from GridSearch:\", grid_log_reg.best_score_)\n\n# Evaluate the best logistic regression estimator on the test set.\nbest_log_reg = grid_log_reg.best_estimator_\ny_pred_best_log = best_log_reg.predict(X_test_scaled)\ny_prob_best_log = best_log_reg.predict_proba(X_test_scaled)[:, 1]\nevaluate_model(\"Logistic Regression (Tuned)\", y_test, y_pred_best_log, y_prob=y_prob_best_log)\n\n# Additionally, adjust the decision threshold (e.g., 0.4 instead of 0.5) for the tuned logistic model.\nthreshold = 0.4\ny_pred_thresh = (y_prob_best_log >= threshold).astype(int)\nevaluate_model(f\"Logistic Regression (Tuned, Threshold {threshold})\", y_test, y_pred_thresh, y_prob=y_prob_best_log)","metadata":{"_uuid":"b65b12cf-48cc-43b2-bfc5-bfd4cd0a9713","_cell_guid":"f1410057-1971-4f65-950e-7518f21afb5b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------------\n# 4. Display Summary of Results\n# ------------------------------\nprint(\"\\nSummary of Results:\")\nfor model, metrics in results.items():\n    print(f\"{model}: {metrics}\")","metadata":{"_uuid":"5e767fac-968c-411a-b221-b8e0a0c2284c","_cell_guid":"8fe73b04-e73c-4bd1-9da6-5f90d868d539","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}